# WYMMS

A mobile app for the WYMMS Project that triggers robot arm movements based on voice recognition and geolocational proximity of 2 devices.

### Features:
* To trigger robot arm movement, two conditions must be met
  * Two devices must be in close proximity of each other
  * One user must utter a specific phrase.
* Box that can be opened by robot arm
* Open box to drop red rose petals upon uttering phrase
* Light up circle of rope lights before or upon uttering phrase (possibly manually)

### Components:
- [ ] Robot Arm
- [x] Raspberry Pi
- [ ] Android & iOS compatible application with LikeAlert and speech recognition functionailities
- [ ] Red Rose Petals
- [ ] Box with a lid
- [ ] Batteries
- [ ] Rope lights positioned as a circle (white or yellow)
- [ ] Something to strap robot arm to tree or above both parties
- [ ] Something to handle communicating between robot arm and mobile app

### Workflow:
* Create LikeAlert app for Android & iOS then put on her device
* Create replit for hosting user data (may also handle robot arm communication)
* Implement speech recognition into LikeAlert (listen on button press)
* Construct robot arm & attach Raspberry Pi
* Get robot arm to move using Raspberry Pi
* Get robot arm to move using voice by talking into LikeAlert (send information via bluetooth)
* Get or make box that's easy to open
* Test in dev
* Order red rose petals
* Order remote controlled battery powered rope lights
* Acquire date, time, place
* Acquire materials to bond project to tree
* Test in stage
* Setup. During setup have someone take her to ICPC for 3 roses.
  Then have that someone take them somewhere else as if it were just another hangout.
  Then have that someone take them to me with other 2 roses in hand and voice listener ready.
* Do the thing
